name: Periodic Apartment Scraper

on:
  schedule:
    # Run roughly every 8 hours, spaced irregularly to appear natural
    - cron: "7 3 * * *"   # 03:07 UTC
    - cron: "13 11 * * *" # 11:13 UTC
    - cron: "28 20 * * *" # 20:28 UTC
  workflow_dispatch:  # Allows manual triggering
  pull_request:
    branches:
      - main

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.13

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright

      - name: Install Playwright dependencies
        run: |
          python -m playwright install

      - name: Run scraper
        run: |
          python scraper.py

      - name: Configure Git for GitHub Pages
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      - name: Create a new branch for Pages
        run: |
          git fetch origin gh-pages
          git checkout gh-pages || git checkout -b gh-pages
          git pull origin gh-pages || echo "No previous content on gh-pages"

      - name: Copy data to Pages branch
        run: |
          cp data/unit_prices.csv .
          git add unit_prices.csv
          git commit -m "Update unit prices"
          git push origin gh-pages

      - name: Upload CSV file (Artifact)
        uses: actions/upload-artifact@v4
        with:
          name: unit_prices
          path: data/unit_prices.csv
